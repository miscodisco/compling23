{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e74142",
   "metadata": {},
   "source": [
    "# HW7: Counting and regular expressions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9044e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re module for working with regular expressions\n",
    "import re\n",
    "# For numerical work, nearly everyone uses numpy\n",
    "from numpy import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e567d",
   "metadata": {},
   "source": [
    "## Part 1: Dictionaries and counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870631c",
   "metadata": {},
   "source": [
    "This notebook partly draws from materials put together by [Dirk Hovy](http://dirkhovy.com/). That's why there's a figure today! Dirk is a computational linguist at the University of Copenhagen. Much of his work tries to explore the intersection of social variables and NLP, working with large online corpora.\n",
    "\n",
    "### The structure of programs\n",
    "\n",
    "Most of programming, irrespective of the language you use, has four main elements:\n",
    "\n",
    "1. ***Assignment***: linking a name to a value. The names are called ***variables***. \n",
    "\n",
    "2. ***Loops***: sometimes we want to do the same thing repeatedly, either a fixed number of times, or\n",
    "until something happens. This is what loops are for. \n",
    "\n",
    "3. ***I/O (Input/Output)***: this refers to everything that has to do with getting information into and\n",
    "out of our programs, e.g. files (opening, closing, reading from or writing to them) or output on\n",
    "the screen.\n",
    "\n",
    "4. ***Control structures***: sometimes, we need to make decisions. I.e., if a variable has a certain \n",
    "value, do `X`, otherwise, do `Y`. Control structures are simple `if...then...else` constructs that evaluate\n",
    "the alternatives and make this decision. \n",
    "\n",
    "Today we'll put these together to do a useful elementary language processing task: getting counts of words in a document. The three main new things we need to learn today are: **reading from files**, **control structures**, and an important new data type the **dictionary** or just **dict**, which is a **mapping** data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31539608",
   "metadata": {},
   "source": [
    "### The dictionary (or \"dict\") data type\n",
    "\n",
    "Python uses the term \"dictionary\" or \"dict\" for a *mapping*: a collection of items of one type mapping to another type. A dictionary is written with curly braces. For example, here's a mapping, from web sites to my passwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5468c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "passwds = {'Amazon': ['curly', 'bulky'], 'Google': 'furry', 'Apple': 'easy',\n",
    "           'Microsoft' : 'easy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be657c6e",
   "metadata": {},
   "source": [
    "No, not really! But it will do. You can access elements from a dict using the same square brackets notation after the dict/variable name, but now using a key which is the first half of the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90ce090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Google password is: furry\n"
     ]
    }
   ],
   "source": [
    "print('My Google password is: ' + passwds['Google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea055c",
   "metadata": {},
   "source": [
    "Trying to get a value for a key that doesn't exist is an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30eb2557",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LinkedIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpasswds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLinkedIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LinkedIN'"
     ]
    }
   ],
   "source": [
    "passwds['LinkedIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5747b",
   "metadata": {},
   "source": [
    "If we want to add a new item to our dictionary, we can simply assign a key a value:\n",
    "```\n",
    "<dictionary>[key] = <value>\n",
    "```\n",
    "\n",
    "Add the value `\"flotilla\"` as my `\"Facebook\"` pasword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0f7222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amazon': ['curly', 'bulky'],\n",
       " 'Google': 'furry',\n",
       " 'Apple': 'easy',\n",
       " 'Microsoft': 'easy',\n",
       " 'Facebook': 'flotilla'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the value \"flotilla\" as my \"Facebook\" pasword:\n",
    "\n",
    "passwds['Facebook'] = 'flotilla'\n",
    "\n",
    "passwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58919145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amazon': ['curly', 'bulky'],\n",
       " 'Google': 'bulky',\n",
       " 'Apple': 'easy',\n",
       " 'Microsoft': 'easy',\n",
       " 'Facebook': 'flotilla'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwds['Google'] = 'bulky'\n",
    "\n",
    "passwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e53a7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amazon': 'sej',\n",
       " 'Google': 'bulkytastytasty',\n",
       " 'Apple': 'easy',\n",
       " 'Microsoft': 'easy',\n",
       " 'Facebook': 'flotilla'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwds['Amazon'] = 'sej'\n",
    "\n",
    "passwds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73a900",
   "metadata": {},
   "source": [
    "In a dict, there can only be one value for a key, but several keys can have the same value. Oh, and while I said a key can have only one value, that value _can_ be a list, which lets you do general relations. A dictionary, unlike a list, isn't ordered. But you can very efficiently get the value for a key. You can also call 3 method `keys()`, `values()`, and `items()` which return list-like values that you can do a `for`-loop over to see all the keys, values, and mappings in the dict.  Try them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79346bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon\n",
      "Google\n",
      "Apple\n",
      "Microsoft\n",
      "Facebook\n"
     ]
    }
   ],
   "source": [
    "for k in passwds.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c6f7e",
   "metadata": {},
   "source": [
    "Note that the keys didn't come out in the order that I wrote them down. You shouldn't rely on the order you wrote things down in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1bd2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "bulkytastytasty\n",
      "easy\n",
      "easy\n",
      "flotilla\n"
     ]
    }
   ],
   "source": [
    "# Now print all the values\n",
    "for k in passwds.values():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db8b3c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon', None)\n",
      "('Google', 'bulkytastytasty')\n",
      "('Apple', 'easy')\n",
      "('Microsoft', 'easy')\n",
      "('Facebook', 'flotilla')\n"
     ]
    }
   ],
   "source": [
    "# Now print all the items\n",
    "for k in passwds.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98af88",
   "metadata": {},
   "source": [
    "Note that the item is something we havent quite seen before – it's two strings wrapped in parentheses. It looks like the arguments to a function. This is different from a list and is called a ***tuple***. It's less important than lists, but we'll come back to them later today....\n",
    "\n",
    "You can check whether a key or value is in a map with the `in` and `not in` operators: `<key> in <dict>`. But that's often tedious to use, so you should also know the cleverer method on dicts `get(key, default)`, which lets you ask for a key, and return its value if it exists, or the default value otherwise. We'll be able to use it later to make our program neater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "239a6ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you don't have an account here\n"
     ]
    }
   ],
   "source": [
    "# See if I have an 'Amazon' password\n",
    "if 'MySpace' in passwds:\n",
    "    print(passwds['Amazon'])\n",
    "else:\n",
    "    print(\"you don't have an account here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc481674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either print my 'Facebook' password or 'None'\n",
    "\n",
    "passwds.get('linkedIN', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e00ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514c7d54",
   "metadata": {},
   "source": [
    "### Word Counts—Dictionaries and Control Structures\n",
    "\n",
    "Last week, we learned about variable assignment, loops, and printing to the screen.\n",
    "There are several useful object types that we have not yet covered, and we need to learn about the constructs that let us\n",
    "test conditions. We will see them in this program, as well as IO for reading from files.\n",
    "\n",
    "We want to know which words occur how often in a\n",
    "file. This is a common elementary text processing step in order to get some idea of your data and to get a sense of its overall topics. The output of such counting is precisely what people use to draw the very common visualization of [word clouds](http://www.wordle.net/). (Even though they're very common, many visualization people don't like them very much; just like pie charts.)\n",
    "\n",
    "Let’s first think about what we have and what we want. We have a ***file***, and we want the\n",
    "counts for the ***words*** in there. So there is a ***file***, ***sentences***, ***words***, and their ***counts***. We need to read the\n",
    "file, get the sentences; for each sentence, get the words, and somehow record their counts. In the end,\n",
    "we just print out the counts again. We can display this like in Figure 1.\n",
    "\n",
    "<img src=\"pics/diagram_word_counts.png\" width=\"500px\">\n",
    "<div align=\"center\">*Figure 1: Flow chart for our word count problem*</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a71054",
   "metadata": {},
   "source": [
    "Now let’s look at the program: it takes a file, reads it in, keeps a running count for each word, and\n",
    "prints those counts at the end. \n",
    "\n",
    "**Make sure to execute each code section as you progress (even the pre-written ones), so that the variables become available to the interpreter.** You won't see any direct output when executing the cell below, but we will need it further on.\n",
    "\n",
    "We first declare the name of the file as a variable, and then actually open the file. \n",
    "`open()` is the function that reads in the file. It takes just one argument: the name of the file we\n",
    "try to open. You can give it a second argument, `'w'` if you want to write to a file, rather than just read from it. Here, we only want to read, so we don't need to specify anything else.\n",
    "\n",
    "Python takes care of some pesky new line and encoding issues, so we won’t worry too much right now about special characters. Go ahead and read a file with runes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6eb3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'debate-clinton.txt'\n",
    "\n",
    "# open the file for reading\n",
    "text_file = open(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e266b5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='debate-clinton.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e49fc5",
   "metadata": {},
   "source": [
    "\n",
    "The result of running `open()` is not the text of the file. It is similar to a list (it's not exactly a list, but an ***iterator*** – that's also what `keys()` gave us above), and we call that list `text_file`, so we can use it later on. This give us a ***handle*** to read through the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a4e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441bcf4",
   "metadata": {},
   "source": [
    "After we have assigned the file hande, we assign the name `word_count` to a ***dictionary***. Here, our keys will be strings (the words), and the values we map them to are numbers (their respective\n",
    "frequencies). If we just use a pair of curly braces, as we\n",
    "did here, we get an empty dictionary. There are no entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8c1b9",
   "metadata": {},
   "source": [
    "After we have declared the dictionary, we start iterating through the file with a `for`-loop.\n",
    "Since `text_file` is an open file, this gives us a list of all the lines. We can\n",
    "thus iterate over them. For each line in the file, we want to do a number of things.\n",
    "That is why the next lines are all indented under the `for`-loop header line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c55256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the open file line by line\n",
    "for line in text_file:\n",
    "    # get rid of the line break at the end\n",
    "    line = line.strip()\n",
    "    # split sentence along spaces\n",
    "    sentence = line.split()\n",
    "    # go through words\n",
    "    for word in sentence:\n",
    "        # check whether word is already in dictionary\n",
    "        if word in word_count:\n",
    "            # if yes: increment\n",
    "            word_count[word] = word_count[word] + 1\n",
    "        # if not, add an entry\n",
    "        else:\n",
    "            word_count[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ecc71",
   "metadata": {},
   "source": [
    "First, we get rid of the line break and any white space at the beginning or end of the line. We could write code to do all these things, but there is an easier (and shorter) way:\n",
    "we use the `strip()` command to remove all that whitespace from the line and assign it to \n",
    "the same name as before (`line`). (*Subtle point here about line break character!*) We made a new object – strings cannot be changed – but we assign it the same name. Whenever we use `line` from now on, it is the “cleaned-up” version of the line. (*Subtle points:* (1) Mutable and immutable objects; (2) If a method returns a new, changed object but doesn't change the original object – this is common and the only way to do things for immutable objects – then it is vital to assign the output of the method to something, or you will lose it. Commonly we assign it back to the same variable name if we conceptually think that we have *improved* the same thing.) \n",
    "\n",
    "We then use the `split()` command we have seen before next.\n",
    "Remember, it splits a sentence at the white space subsequences into a list, so if we had extra white spaces,\n",
    "it would create empty entries in our list. The list of strings resulting from `split()` is assigned to\n",
    "`sentence`, and we then iterate over that list. We have seen this before, so I will skip to the next\n",
    "interesting part here: control structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8c14f",
   "metadata": {},
   "source": [
    "After we have read the whole file, we close it with the `close()` command on the file variable. The dot tells us that it is a property of files. Note \n",
    "that this line is no longer indented under the `for`-loop, but at the same level. This means that it is only\n",
    "executed once we have completed all our iterations of the for-loop, in this case, after we have read all\n",
    "lines in the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2784f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the file after reading\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd53ec",
   "metadata": {},
   "source": [
    "### Control Structures\n",
    "\n",
    "So far, we have simply executed one command after the next. We never had to make a decision or\n",
    "choose among options. Now we have to. If a word is already listed in our dictionary, we want to\n",
    "increase its count by one (we know how to do that). If the word is not in our dictionary, however, we\n",
    "have to make an entry. Otherwise, we would try to increment a count that does not even exist (you\n",
    "cannot look up something that is not in the dictionary).\n",
    "\n",
    "To make the decision what to do, we use the `if...then...else` structure or ***conditional***.\n",
    "The structure of the conditional is simple:\n",
    "```\n",
    "if <condition is true>:\n",
    "    <action1>\n",
    "else:\n",
    "    <action2>\n",
    "```\n",
    "\n",
    "Here `<condition>` is another type of variable, a so-called ***boolean***. They are named after the \n",
    "mathematician Boole, and have only two values: `True` and `False` (note the capital spelling!). In our\n",
    "case, the value comes from the outcome of the condition `word in word_count` to check whether\n",
    "the dictionary `word_count` contains the key word. **`in`** is one of Python’s reserved words. You can\n",
    "use it to check whether a variable is in a dictionary, a list, or other ***collections***.\n",
    "Sometimes, there are more than just two cases (something being true or false) that we would\n",
    "like to account for. In that case, we can check for more conditions:\n",
    "```\n",
    "if <condition1 is true>:\n",
    "    <action1>\n",
    "elif <condition2 is true>:\n",
    "    <action2>\n",
    "elif <condition3 is true>:\n",
    "    <action3>\n",
    "else:\n",
    "    <action4>\n",
    "```\n",
    "\n",
    "You can add as many `elif` cases as you want! We will see an example of this in the next section.\n",
    "\n",
    "So if the word we look at is indeed in our dictionary, we increment its count by one. \n",
    "This puts the current word in the dictionary and sets its counter to 1.\n",
    "\n",
    "Write your own control structure that checks whether `\"Amazon\"` is a key in `passwds`, and prints `\"Your password is <passwd>\"` if there is one and `\"You don't have an Amazon account!\"` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300140db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9ad6e5",
   "metadata": {},
   "source": [
    "In our program, we finally want to print all the counts we have collected to the screen. We use another `for`-loop. This time, it iterates over a list of ***tuples***. Tuples are a lot like lists, with the big difference that they \n",
    "have a fixed size. They are less flexible than lists. In Python, we denote tuples by round brackets\n",
    "(instead of square ones as for lists). The function `items()` of a dictionary returns a list of \n",
    "tuples of each key and its respective value. We use that and assign them to `word` and `frequency`, respectively. We print each word and its frequency (provided it occurred more than once) separated by a space, (that is why there is a comma in the `print()` statement, see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7b7e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are 34\n",
      "Well, 26\n",
      "and 113\n",
      "to 220\n",
      "for 37\n",
      "in 90\n",
      "this 26\n",
      "is 51\n",
      "what 37\n",
      "of 122\n",
      "we 104\n",
      "be 54\n",
      "I 133\n",
      "think 36\n",
      "about 33\n",
      "a 105\n",
      "have 81\n",
      "that 108\n",
      "not 34\n",
      "at 33\n",
      "the 228\n",
      "need 23\n",
      "with 35\n",
      "your 23\n",
      "We 24\n",
      "more 21\n",
      "do 32\n",
      "you 50\n",
      "And 69\n",
      "people 25\n",
      "going 24\n",
      "it 43\n",
      "on 25\n",
      "our 38\n",
      "can 28\n",
      "has 29\n",
      "would 35\n",
      "was 25\n",
      "he 32\n",
      "-- 29\n",
      "as 23\n",
      "But 23\n"
     ]
    }
   ],
   "source": [
    "# take each pair of word and frequency in the dictionary\n",
    "for (word, frequency) in word_count.items():\n",
    "    if frequency > 20:\n",
    "        print(word, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65b022",
   "metadata": {},
   "source": [
    "Well, we've learned a fair bit here. We have learned how to read in a text file, how to use control structures, and we have\n",
    "seen the new object types dictionaries and tuples.\n",
    "You have now seen a lot of the basics of Python! While there are a lot of other things that you *can* learn – and, gosh, I'm going to attempt to teach quite a few of them — you can actually write quite a bit of basic text processing using just these elements. Many of the things that we'll learn later provide faster, more powerful, more convenient ways to do things that you _could_ do with just these elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687655d",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Doing more with word counts from the Clinton-Trump debate\n",
    "\n",
    "Try to do all of these things, and end up with a decent program at the end that does all this stuff.\n",
    "\n",
    "The above program got word counts from the file `'debate-clinton.txt'`. It was hardcoded to do so. But we also want word counts from `'debate-trump.txt'`. So, what we want is a function that can count words in _any_ file.  We might structure our program as two functions:\n",
    "\n",
    "1. A function that takes a string filename and returns a dict from words to their counts in the file.\n",
    "\n",
    "2. A function that takes a dict of word counts and prints the word counts\n",
    "\n",
    "You are welcome to copy and paste any code from above to get this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef95f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for collecting word counts from a file\n",
    "# Don't forget to close the file after you have read it in!\n",
    "\n",
    "def word_counter(file_name):\n",
    "    \n",
    "    text_file = open(file_name)\n",
    "    word_count_dict = {}\n",
    "    \n",
    "    \n",
    "    for line in text_file:\n",
    "        # get rid of the line break at the end\n",
    "        line = line.strip()\n",
    "        # split sentence along spaces\n",
    "        sentence = line.split()\n",
    "        # go through words\n",
    "        for word in sentence:\n",
    "            # check whether word is already in dictionary\n",
    "            if word in word_count_dict:\n",
    "                # if yes: increment\n",
    "                word_count_dict[word] = word_count_dict[word] + 1\n",
    "            # if not, add an entry\n",
    "            else:\n",
    "                word_count_dict[word] = 1\n",
    "                \n",
    "    text_file.close()\n",
    "    \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d0b4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for printing word counts from a dict\n",
    "\n",
    "def print_word_count(word_count_dict):\n",
    "\n",
    "    for (word, frequency) in word_count_dict.items():\n",
    "        if frequency > 20:\n",
    "            print(word, frequency)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c0fcfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'How': 4,\n",
       " 'are': 34,\n",
       " 'you,': 3,\n",
       " 'Donald?': 1,\n",
       " 'Well,': 26,\n",
       " 'thank': 1,\n",
       " 'Lester,': 3,\n",
       " 'and': 113,\n",
       " 'thanks': 1,\n",
       " 'to': 220,\n",
       " 'Hofstra': 1,\n",
       " 'for': 37,\n",
       " 'hosting': 1,\n",
       " 'us.': 2,\n",
       " 'The': 6,\n",
       " 'central': 1,\n",
       " 'question': 4,\n",
       " 'in': 90,\n",
       " 'this': 26,\n",
       " 'election': 1,\n",
       " 'is': 51,\n",
       " 'really': 18,\n",
       " 'what': 37,\n",
       " 'kind': 10,\n",
       " 'of': 122,\n",
       " 'country': 8,\n",
       " 'we': 104,\n",
       " 'want': 18,\n",
       " 'be': 54,\n",
       " 'future': 3,\n",
       " \"we'll\": 5,\n",
       " 'build': 3,\n",
       " 'together.': 2,\n",
       " 'Today': 1,\n",
       " 'my': 9,\n",
       " \"granddaughter's\": 1,\n",
       " 'second': 3,\n",
       " 'birthday,': 1,\n",
       " 'so': 19,\n",
       " 'I': 133,\n",
       " 'think': 36,\n",
       " 'about': 33,\n",
       " 'a': 105,\n",
       " 'lot.': 1,\n",
       " 'First,': 2,\n",
       " 'have': 81,\n",
       " 'an': 11,\n",
       " 'economy': 5,\n",
       " 'that': 108,\n",
       " 'works': 2,\n",
       " 'everyone,': 2,\n",
       " 'not': 34,\n",
       " 'just': 14,\n",
       " 'those': 7,\n",
       " 'at': 33,\n",
       " 'the': 228,\n",
       " 'top.': 3,\n",
       " 'That': 12,\n",
       " 'means': 4,\n",
       " 'need': 23,\n",
       " 'new': 9,\n",
       " 'jobs,': 5,\n",
       " 'good': 13,\n",
       " 'with': 35,\n",
       " 'rising': 3,\n",
       " 'incomes.': 2,\n",
       " 'us': 15,\n",
       " 'invest': 4,\n",
       " 'you.': 5,\n",
       " 'your': 23,\n",
       " 'future.': 1,\n",
       " 'jobs': 9,\n",
       " 'infrastructure,': 1,\n",
       " 'advanced': 1,\n",
       " 'manufacturing,': 1,\n",
       " 'innovation': 1,\n",
       " 'technology,': 1,\n",
       " 'clean,': 1,\n",
       " 'renewable': 1,\n",
       " 'energy,': 1,\n",
       " 'small': 3,\n",
       " 'business,': 3,\n",
       " 'because': 20,\n",
       " 'most': 4,\n",
       " 'will': 19,\n",
       " 'come': 5,\n",
       " 'from': 17,\n",
       " 'business.': 2,\n",
       " 'We': 24,\n",
       " 'also': 12,\n",
       " 'make': 16,\n",
       " 'fairer.': 1,\n",
       " 'starts': 1,\n",
       " 'raising': 2,\n",
       " 'national': 4,\n",
       " 'minimum': 2,\n",
       " 'wage': 1,\n",
       " 'guarantee,': 1,\n",
       " 'finally,': 1,\n",
       " 'equal': 2,\n",
       " 'pay': 7,\n",
       " \"women's\": 1,\n",
       " 'work.': 4,\n",
       " 'see': 9,\n",
       " 'more': 21,\n",
       " 'companies': 2,\n",
       " 'do': 32,\n",
       " 'profit-sharing.': 1,\n",
       " 'If': 3,\n",
       " 'you': 50,\n",
       " 'help': 4,\n",
       " 'create': 4,\n",
       " 'profits,': 1,\n",
       " 'should': 15,\n",
       " 'able': 6,\n",
       " 'share': 3,\n",
       " 'them,': 2,\n",
       " 'executives': 1,\n",
       " 'And': 69,\n",
       " 'support': 7,\n",
       " 'people': 25,\n",
       " 'who': 19,\n",
       " 'struggling': 1,\n",
       " 'balance': 2,\n",
       " 'family': 3,\n",
       " \"I've\": 11,\n",
       " 'heard': 4,\n",
       " 'many': 10,\n",
       " 'difficult': 2,\n",
       " 'choices': 1,\n",
       " 'face': 3,\n",
       " 'stresses': 1,\n",
       " \"you're\": 6,\n",
       " 'under.': 1,\n",
       " 'So': 20,\n",
       " \"let's\": 6,\n",
       " 'paid': 6,\n",
       " 'leave,': 1,\n",
       " 'earned': 1,\n",
       " 'sick': 1,\n",
       " 'days.': 1,\n",
       " \"Let's\": 1,\n",
       " 'sure': 5,\n",
       " 'affordable': 1,\n",
       " 'child': 1,\n",
       " 'care': 2,\n",
       " 'debt-free': 2,\n",
       " 'college.': 1,\n",
       " 'going': 24,\n",
       " 'it?': 1,\n",
       " \"We're\": 6,\n",
       " 'it': 43,\n",
       " 'by': 11,\n",
       " 'having': 5,\n",
       " 'wealthy': 5,\n",
       " 'their': 19,\n",
       " 'fair': 5,\n",
       " 'close': 2,\n",
       " 'corporate': 2,\n",
       " 'loopholes.': 1,\n",
       " 'Finally,': 1,\n",
       " 'tonight': 1,\n",
       " 'on': 25,\n",
       " 'stage': 1,\n",
       " 'together,': 1,\n",
       " 'Donald': 15,\n",
       " 'Trump': 2,\n",
       " 'I.': 1,\n",
       " 'Donald,': 3,\n",
       " \"it's\": 13,\n",
       " 'debate': 1,\n",
       " 'where': 7,\n",
       " 'talking': 1,\n",
       " 'important': 7,\n",
       " 'issues': 2,\n",
       " 'facing': 4,\n",
       " 'our': 38,\n",
       " 'country.': 6,\n",
       " 'You': 13,\n",
       " 'judge': 1,\n",
       " 'us,': 2,\n",
       " 'can': 28,\n",
       " 'shoulder': 1,\n",
       " 'immense,': 1,\n",
       " 'awesome': 1,\n",
       " 'responsibilities': 3,\n",
       " 'presidency,': 1,\n",
       " 'put': 8,\n",
       " 'into': 9,\n",
       " 'action': 1,\n",
       " 'plans': 3,\n",
       " 'life': 2,\n",
       " 'better.': 1,\n",
       " 'hope': 5,\n",
       " 'earn': 1,\n",
       " 'vote': 3,\n",
       " 'November': 1,\n",
       " '8th.': 1,\n",
       " 'trade': 7,\n",
       " 'issue.': 2,\n",
       " 'Of': 1,\n",
       " 'course,': 2,\n",
       " '5': 1,\n",
       " 'percent': 2,\n",
       " \"world's\": 1,\n",
       " 'population;': 1,\n",
       " 'other': 6,\n",
       " '95': 1,\n",
       " 'percent.': 4,\n",
       " 'smart,': 2,\n",
       " 'deals.': 2,\n",
       " 'also,': 1,\n",
       " 'though,': 1,\n",
       " 'tax': 15,\n",
       " 'system': 1,\n",
       " 'rewards': 1,\n",
       " 'work': 10,\n",
       " 'financial': 3,\n",
       " 'transactions.': 1,\n",
       " 'plan': 5,\n",
       " 'has': 29,\n",
       " 'forth': 2,\n",
       " 'would': 35,\n",
       " 'trickle-down': 1,\n",
       " 'economics': 1,\n",
       " 'all': 11,\n",
       " 'over': 8,\n",
       " 'again.': 4,\n",
       " 'In': 4,\n",
       " 'fact,': 5,\n",
       " 'extreme': 1,\n",
       " 'version,': 1,\n",
       " 'biggest': 4,\n",
       " 'cuts': 2,\n",
       " 'top': 2,\n",
       " 'than': 3,\n",
       " \"we've\": 13,\n",
       " 'ever': 7,\n",
       " 'had.': 1,\n",
       " 'call': 2,\n",
       " 'trumped-up': 2,\n",
       " 'trickle-down,': 1,\n",
       " \"that's\": 12,\n",
       " 'exactly': 1,\n",
       " 'be.': 3,\n",
       " 'how': 9,\n",
       " 'grow': 2,\n",
       " 'economy.': 5,\n",
       " 'different': 6,\n",
       " 'view': 1,\n",
       " \"what's\": 2,\n",
       " 'best': 3,\n",
       " 'growing': 1,\n",
       " 'economy,': 3,\n",
       " 'investments': 2,\n",
       " 'actually': 7,\n",
       " 'produce': 1,\n",
       " 'somewhat': 1,\n",
       " 'perspectives.': 1,\n",
       " 'understand': 3,\n",
       " 'that.': 11,\n",
       " 'know,': 13,\n",
       " 'was': 25,\n",
       " 'very': 12,\n",
       " 'fortunate': 1,\n",
       " 'his': 13,\n",
       " 'life,': 1,\n",
       " 'benefit.': 3,\n",
       " 'He': 10,\n",
       " 'started': 2,\n",
       " 'business': 10,\n",
       " '$14': 1,\n",
       " 'million,': 1,\n",
       " 'borrowed': 1,\n",
       " 'father,': 1,\n",
       " 'he': 32,\n",
       " 'believes': 1,\n",
       " 'people,': 4,\n",
       " 'better': 5,\n",
       " 'off': 3,\n",
       " 'everything': 6,\n",
       " 'out': 13,\n",
       " 'there.': 1,\n",
       " \"don't\": 10,\n",
       " 'buy': 4,\n",
       " 'experience.': 1,\n",
       " 'My': 1,\n",
       " 'father': 2,\n",
       " 'small-businessman.': 1,\n",
       " 'worked': 3,\n",
       " 'hard.': 2,\n",
       " 'printed': 1,\n",
       " 'drapery': 2,\n",
       " 'fabrics': 2,\n",
       " 'long': 3,\n",
       " 'tables,': 1,\n",
       " 'pulled': 1,\n",
       " 'went': 3,\n",
       " 'down': 3,\n",
       " 'silkscreen': 1,\n",
       " 'dumped': 1,\n",
       " 'paint': 1,\n",
       " 'took': 3,\n",
       " 'squeegee': 1,\n",
       " 'kept': 2,\n",
       " 'going.': 1,\n",
       " 'believe': 4,\n",
       " 'middle': 5,\n",
       " 'class,': 4,\n",
       " 'education,': 2,\n",
       " 'skills,': 1,\n",
       " 'future,': 1,\n",
       " 'grow.': 1,\n",
       " \"That's\": 6,\n",
       " 'stop': 1,\n",
       " 'remember': 1,\n",
       " 'were': 9,\n",
       " 'eight': 2,\n",
       " 'years': 5,\n",
       " 'ago.': 2,\n",
       " 'had': 7,\n",
       " 'worst': 4,\n",
       " 'crisis,': 1,\n",
       " 'Great': 1,\n",
       " 'Recession,': 1,\n",
       " 'since': 3,\n",
       " '1930s.': 1,\n",
       " 'large': 1,\n",
       " 'part': 4,\n",
       " 'policies': 2,\n",
       " 'slashed': 1,\n",
       " 'taxes': 3,\n",
       " 'wealthy,': 3,\n",
       " 'failed': 2,\n",
       " 'eyes': 1,\n",
       " 'Wall': 2,\n",
       " 'Street,': 1,\n",
       " 'created': 1,\n",
       " 'perfect': 1,\n",
       " 'storm.': 1,\n",
       " 'one': 16,\n",
       " 'rooted': 1,\n",
       " 'housing': 1,\n",
       " 'crisis.': 1,\n",
       " 'said,': 5,\n",
       " 'back': 7,\n",
       " '2006,': 1,\n",
       " '\"Gee,': 1,\n",
       " 'does': 3,\n",
       " 'collapse,': 1,\n",
       " 'then': 5,\n",
       " 'go': 9,\n",
       " 'some': 11,\n",
       " 'money.\"': 1,\n",
       " 'did': 7,\n",
       " 'collapse.': 1,\n",
       " 'Nine': 1,\n",
       " 'million': 9,\n",
       " '--': 29,\n",
       " 'nine': 2,\n",
       " 'lost': 2,\n",
       " 'jobs.': 2,\n",
       " 'Five': 1,\n",
       " 'homes.': 1,\n",
       " '$13': 1,\n",
       " 'trillion': 4,\n",
       " 'wealth': 1,\n",
       " 'wiped': 1,\n",
       " 'out.': 2,\n",
       " 'Now,': 2,\n",
       " 'abyss.': 1,\n",
       " 'been': 11,\n",
       " 'easy.': 1,\n",
       " \"we're\": 12,\n",
       " 'now': 5,\n",
       " 'precipice': 1,\n",
       " 'potentially': 1,\n",
       " 'much': 5,\n",
       " 'but': 13,\n",
       " 'last': 2,\n",
       " 'thing': 3,\n",
       " 'first': 4,\n",
       " 'place.': 2,\n",
       " 'Independent': 1,\n",
       " 'experts': 1,\n",
       " 'looked': 5,\n",
       " 'proposed': 4,\n",
       " \"Donald's\": 4,\n",
       " 'proposed,': 2,\n",
       " 'basically': 1,\n",
       " \"they've\": 4,\n",
       " 'said': 8,\n",
       " 'this,': 2,\n",
       " 'if': 13,\n",
       " 'plan,': 2,\n",
       " 'which': 6,\n",
       " 'blow': 1,\n",
       " 'up': 9,\n",
       " 'debt': 4,\n",
       " '$5': 3,\n",
       " 'instances': 1,\n",
       " 'disadvantage': 1,\n",
       " 'middle-class': 2,\n",
       " 'families': 4,\n",
       " 'compared': 1,\n",
       " 'effect,': 1,\n",
       " 'lose': 2,\n",
       " '3.5': 2,\n",
       " 'maybe': 5,\n",
       " 'another': 2,\n",
       " 'recession.': 2,\n",
       " \"They've\": 2,\n",
       " 'OK,': 1,\n",
       " 'intend': 3,\n",
       " 'get': 15,\n",
       " 'done,': 1,\n",
       " '10': 2,\n",
       " 'making': 4,\n",
       " 'Take': 1,\n",
       " 'clean': 2,\n",
       " 'energy.': 1,\n",
       " 'Some': 2,\n",
       " 'clean-': 1,\n",
       " 'energy': 2,\n",
       " 'superpower': 1,\n",
       " '21st': 1,\n",
       " 'century.': 1,\n",
       " 'thinks': 1,\n",
       " 'climate': 1,\n",
       " 'change': 1,\n",
       " 'hoax': 1,\n",
       " 'perpetrated': 1,\n",
       " 'Chinese.': 1,\n",
       " 'real.': 2,\n",
       " 'science': 1,\n",
       " 'grip': 1,\n",
       " 'deal': 6,\n",
       " 'it,': 5,\n",
       " 'both': 5,\n",
       " 'home': 4,\n",
       " 'abroad.': 1,\n",
       " \"here's\": 1,\n",
       " 'do.': 11,\n",
       " 'deploy': 1,\n",
       " 'half': 1,\n",
       " 'billion': 2,\n",
       " 'solar': 1,\n",
       " 'panels.': 1,\n",
       " 'enough': 1,\n",
       " 'power': 1,\n",
       " 'every': 2,\n",
       " 'home.': 2,\n",
       " 'modern': 1,\n",
       " 'electric': 1,\n",
       " 'grid.': 1,\n",
       " 'lot': 16,\n",
       " 'jobs;': 1,\n",
       " 'economic': 1,\n",
       " 'activity.': 1,\n",
       " 'tried': 2,\n",
       " 'specific': 1,\n",
       " 'do,': 2,\n",
       " 'am': 3,\n",
       " 'determined': 1,\n",
       " 'moving': 1,\n",
       " 'again,': 4,\n",
       " 'building': 2,\n",
       " 'progress': 1,\n",
       " 'made': 5,\n",
       " 'years,': 2,\n",
       " 'never': 5,\n",
       " 'got': 14,\n",
       " 'trouble': 1,\n",
       " 'actually...': 1,\n",
       " 'actually,': 1,\n",
       " 'thought': 1,\n",
       " 'quite': 2,\n",
       " 'bit.': 1,\n",
       " 'well,': 5,\n",
       " 'long.': 1,\n",
       " 'husband': 1,\n",
       " 'pretty': 1,\n",
       " 'job': 3,\n",
       " '1990s.': 1,\n",
       " 'again...': 1,\n",
       " '...': 15,\n",
       " 'balanced': 1,\n",
       " 'budget...': 1,\n",
       " 'Incomes': 1,\n",
       " 'everybody.': 1,\n",
       " 'Manufacturing': 1,\n",
       " '1990s,': 1,\n",
       " 'look': 7,\n",
       " 'facts.': 2,\n",
       " 'When': 2,\n",
       " 'Senate,': 1,\n",
       " 'number': 4,\n",
       " 'deals': 2,\n",
       " 'came': 1,\n",
       " 'before': 2,\n",
       " 'me,': 1,\n",
       " 'held': 1,\n",
       " 'them': 10,\n",
       " 'same': 4,\n",
       " 'test.': 1,\n",
       " 'Will': 2,\n",
       " 'they': 19,\n",
       " 'America?': 2,\n",
       " 'raise': 1,\n",
       " 'incomes': 1,\n",
       " 'security?': 1,\n",
       " 'voted': 2,\n",
       " 'for.': 1,\n",
       " 'one,': 2,\n",
       " 'multinational': 1,\n",
       " 'known': 1,\n",
       " 'as': 23,\n",
       " 'CAFTA,': 1,\n",
       " 'against.': 1,\n",
       " 'hold': 2,\n",
       " 'standards': 1,\n",
       " 'these': 5,\n",
       " 'But': 23,\n",
       " 'assume': 1,\n",
       " 'only': 6,\n",
       " 'challenge': 2,\n",
       " \"I'm\": 7,\n",
       " 'special': 1,\n",
       " 'prosecutor.': 1,\n",
       " 'enforce': 1,\n",
       " 'have,': 2,\n",
       " 'accountable.': 1,\n",
       " 'secretary': 3,\n",
       " 'state,': 2,\n",
       " 'increased': 2,\n",
       " 'American': 9,\n",
       " 'exports': 2,\n",
       " 'globally': 1,\n",
       " '30': 1,\n",
       " 'China': 1,\n",
       " '50': 2,\n",
       " 'know': 10,\n",
       " 'helped': 1,\n",
       " 'senator,': 1,\n",
       " 'Donald...': 1,\n",
       " 'state...': 1,\n",
       " 'done': 4,\n",
       " 'lot...': 1,\n",
       " 'opinion.': 2,\n",
       " 'accurate.': 1,\n",
       " 'against': 3,\n",
       " 'once': 1,\n",
       " 'finally': 2,\n",
       " 'negotiated': 1,\n",
       " 'terms': 1,\n",
       " 'laid': 2,\n",
       " 'wrote': 2,\n",
       " 'in...': 1,\n",
       " 'No.': 1,\n",
       " 'live': 2,\n",
       " 'own': 1,\n",
       " 'reality,': 1,\n",
       " 'facts': 2,\n",
       " 'say': 7,\n",
       " 'hoped': 1,\n",
       " 'deal,': 1,\n",
       " 'when': 16,\n",
       " 'negotiated...': 1,\n",
       " 'responsible': 1,\n",
       " 'for,': 2,\n",
       " 'concluded': 2,\n",
       " \"wasn't.\": 1,\n",
       " 'book...': 1,\n",
       " 'even': 6,\n",
       " 'announced.': 1,\n",
       " 'Look,': 2,\n",
       " 'there': 13,\n",
       " 'differences...': 1,\n",
       " 'There': 5,\n",
       " 'are...': 1,\n",
       " 'views': 1,\n",
       " 'country,': 2,\n",
       " 'leadership': 2,\n",
       " 'world.': 2,\n",
       " 'why': 6,\n",
       " 'incomes,': 1,\n",
       " 'investments,': 1,\n",
       " 'add': 3,\n",
       " 'debt.': 2,\n",
       " 'oh,': 1,\n",
       " 'written': 1,\n",
       " 'book': 1,\n",
       " 'it.': 2,\n",
       " \"It's\": 7,\n",
       " 'called': 6,\n",
       " '\"Stronger': 1,\n",
       " 'Together.\"': 1,\n",
       " 'pick': 1,\n",
       " 'tomorrow': 1,\n",
       " 'bookstore...': 1,\n",
       " 'or': 6,\n",
       " 'airport': 1,\n",
       " 'near': 3,\n",
       " 'strong': 1,\n",
       " 'growth,': 2,\n",
       " 'sustained': 1,\n",
       " 'growth.': 1,\n",
       " 'robust': 1,\n",
       " 'set': 1,\n",
       " 'plans.': 1,\n",
       " 'plans,': 1,\n",
       " 'mine': 1,\n",
       " 'yours': 1,\n",
       " 'explode': 1,\n",
       " \"can't\": 2,\n",
       " 'left': 1,\n",
       " 'stand.': 1,\n",
       " 'assumed': 1,\n",
       " 'charges': 1,\n",
       " 'claims,': 1,\n",
       " 'so...': 1,\n",
       " 'taken': 6,\n",
       " 'page': 1,\n",
       " 'website,': 1,\n",
       " 'HillaryClinton.com,': 1,\n",
       " 'turned': 1,\n",
       " 'fact-checker.': 1,\n",
       " 'real-time': 1,\n",
       " 'are,': 2,\n",
       " 'please': 1,\n",
       " 'take': 5,\n",
       " 'look.': 1,\n",
       " 'Because': 2,\n",
       " 'proposed...': 1,\n",
       " 'penny': 1,\n",
       " 'debt,': 1,\n",
       " 'What': 2,\n",
       " 'cut': 1,\n",
       " 'regulations': 1,\n",
       " 'streamline': 1,\n",
       " 'businesses.': 1,\n",
       " 'gains': 1,\n",
       " 'time': 2,\n",
       " 'corporations': 1,\n",
       " 'least': 1,\n",
       " 'fight': 1,\n",
       " 'ISIS.': 3,\n",
       " 'No,': 3,\n",
       " 'not.': 3,\n",
       " 'please,': 1,\n",
       " 'fact': 3,\n",
       " 'checkers,': 1,\n",
       " 'feeling': 2,\n",
       " 'by,': 1,\n",
       " 'end': 2,\n",
       " 'evening,': 1,\n",
       " 'blamed': 1,\n",
       " 'happened.': 1,\n",
       " 'Why': 1,\n",
       " 'not?': 2,\n",
       " 'Yeah,': 2,\n",
       " 'start': 2,\n",
       " 'clock': 1,\n",
       " 'Lester.': 3,\n",
       " \"We've\": 4,\n",
       " 'proposals.': 1,\n",
       " 'changes': 1,\n",
       " 'rates': 1,\n",
       " 'kinds': 5,\n",
       " 'proposals': 1,\n",
       " 'referring': 1,\n",
       " 'cause': 2,\n",
       " 'repatriation,': 1,\n",
       " 'bringing': 1,\n",
       " 'money': 3,\n",
       " 'stranded': 1,\n",
       " 'overseas.': 1,\n",
       " 'happen': 3,\n",
       " 'way': 2,\n",
       " 'loophole,': 1,\n",
       " 'advantage': 1,\n",
       " \"You've\": 1,\n",
       " 'approach': 1,\n",
       " 'a...': 1,\n",
       " '$4': 1,\n",
       " 'benefit': 1,\n",
       " 'family.': 1,\n",
       " 'proposing...': 1,\n",
       " 'is...': 2,\n",
       " 'trickle-down.': 1,\n",
       " 'Trickle-down': 1,\n",
       " 'It': 8,\n",
       " 'mess': 1,\n",
       " 'in,': 1,\n",
       " '2008': 1,\n",
       " '2009.': 1,\n",
       " 'Slashing': 1,\n",
       " \"hasn't\": 1,\n",
       " 'worked.': 2,\n",
       " 'saying,': 2,\n",
       " 'hey,': 1,\n",
       " 'contributions': 1,\n",
       " 'rebuild': 1,\n",
       " 'class.': 1,\n",
       " 'top-down': 1,\n",
       " 'America.': 1,\n",
       " 'investing': 1,\n",
       " 'college': 2,\n",
       " 'young': 7,\n",
       " 'helping': 1,\n",
       " 'refinance': 1,\n",
       " 'lower': 1,\n",
       " 'rate.': 2,\n",
       " 'Those': 1,\n",
       " 'things': 6,\n",
       " 'boost': 1,\n",
       " 'Broad-based,': 1,\n",
       " 'inclusive': 1,\n",
       " 'growth': 1,\n",
       " 'America,': 1,\n",
       " 'advantages': 1,\n",
       " \"you've\": 3,\n",
       " 'seen': 3,\n",
       " 'example': 1,\n",
       " 'bait-and-': 1,\n",
       " 'switch': 2,\n",
       " 'here.': 2,\n",
       " 'For': 1,\n",
       " '40': 3,\n",
       " 'everyone': 3,\n",
       " 'running': 1,\n",
       " 'president': 2,\n",
       " 'released': 1,\n",
       " 'returns.': 1,\n",
       " 'nearly,': 1,\n",
       " 'think,': 2,\n",
       " '39,': 1,\n",
       " 'returns,': 2,\n",
       " 'IRS': 1,\n",
       " 'clear': 4,\n",
       " 'no': 6,\n",
       " 'prohibition': 2,\n",
       " 'releasing': 1,\n",
       " 'under': 2,\n",
       " 'audit.': 1,\n",
       " 'ask': 1,\n",
       " 'yourself,': 1,\n",
       " \"won't\": 1,\n",
       " 'release': 2,\n",
       " 'returns?': 1,\n",
       " 'may': 3,\n",
       " 'couple': 2,\n",
       " 'reasons.': 1,\n",
       " \"he's\": 11,\n",
       " 'rich': 1,\n",
       " 'says': 3,\n",
       " 'is.': 1,\n",
       " 'Second,': 1,\n",
       " 'charitable': 1,\n",
       " 'claims': 1,\n",
       " 'Third,': 1,\n",
       " 'dealings,': 1,\n",
       " 'told': 1,\n",
       " 'through': 1,\n",
       " 'investigative': 1,\n",
       " 'reporting': 1,\n",
       " 'owes': 2,\n",
       " '$650': 1,\n",
       " 'Street': 1,\n",
       " 'foreign': 4,\n",
       " 'banks.': 1,\n",
       " 'Or': 1,\n",
       " \"doesn't\": 1,\n",
       " 'watching': 1,\n",
       " 'tonight,': 1,\n",
       " 'nothing': 1,\n",
       " 'federal': 5,\n",
       " 'taxes,': 1,\n",
       " \"anybody's\": 1,\n",
       " 'turn': 2,\n",
       " 'state': 3,\n",
       " 'authorities': 1,\n",
       " 'trying': 5,\n",
       " 'casino': 1,\n",
       " 'license,': 1,\n",
       " 'showed': 1,\n",
       " \"didn't\": 2,\n",
       " 'any': 6,\n",
       " 'income': 2,\n",
       " 'tax.': 1,\n",
       " 'zero,': 1,\n",
       " 'zero': 3,\n",
       " 'troops,': 2,\n",
       " 'vets,': 1,\n",
       " 'schools': 2,\n",
       " 'health.': 1,\n",
       " 'probably': 1,\n",
       " 'enthusiastic': 1,\n",
       " 'rest': 1,\n",
       " 'real': 1,\n",
       " 'reasons': 3,\n",
       " 'must': 1,\n",
       " 'something': 5,\n",
       " 'important,': 1,\n",
       " 'terrible,': 1,\n",
       " 'hide.': 1,\n",
       " 'disclosure': 1,\n",
       " 'statements,': 1,\n",
       " 'give': 5,\n",
       " 'They': 5,\n",
       " 'details': 1,\n",
       " 'returns': 1,\n",
       " 'would.': 1,\n",
       " 'seems': 1,\n",
       " 'me': 4,\n",
       " 'deserve': 3,\n",
       " 'see.': 1,\n",
       " 'reason': 1,\n",
       " \"there's\": 2,\n",
       " 'hiding.': 2,\n",
       " 'guess.': 1,\n",
       " \"We'll\": 1,\n",
       " 'keep': 3,\n",
       " 'guessing': 1,\n",
       " 'might': 2,\n",
       " 'is,': 2,\n",
       " 'White': 1,\n",
       " 'House,': 1,\n",
       " 'conflicts?': 1,\n",
       " 'Who': 2,\n",
       " 'owe': 1,\n",
       " 'to?': 1,\n",
       " 'answers': 1,\n",
       " 'that,': 3,\n",
       " 'provide': 4,\n",
       " 'them.': 6,\n",
       " 'mistake': 1,\n",
       " 'using': 2,\n",
       " 'private': 2,\n",
       " 'e-': 1,\n",
       " 'mail.': 1,\n",
       " 'would,': 1,\n",
       " 'obviously,': 1,\n",
       " 'differently.': 1,\n",
       " 'excuses.': 1,\n",
       " 'mistake,': 1,\n",
       " 'responsibility': 1,\n",
       " \"haven't\": 1,\n",
       " 'years.': 1,\n",
       " 'important...': 1,\n",
       " 'main': 1,\n",
       " 'claim': 2,\n",
       " 'United': 5,\n",
       " 'States': 2,\n",
       " 'talk': 6,\n",
       " 'campaign': 2,\n",
       " 'manager': 1,\n",
       " 'built': 1,\n",
       " 'businesses': 2,\n",
       " 'backs': 1,\n",
       " 'little': 1,\n",
       " 'guys.': 1,\n",
       " 'And,': 4,\n",
       " 'indeed,': 1,\n",
       " 'met': 3,\n",
       " 'stiffed': 2,\n",
       " 'businesses,': 1,\n",
       " 'Donald.': 1,\n",
       " 'dishwashers,': 1,\n",
       " 'painters,': 1,\n",
       " 'architects,': 1,\n",
       " 'glass': 1,\n",
       " 'installers,': 3,\n",
       " 'marble': 1,\n",
       " 'like': 3,\n",
       " 'dad': 1,\n",
       " 'was,': 1,\n",
       " 'refused': 2,\n",
       " 'finished': 1,\n",
       " 'asked': 2,\n",
       " 'architect': 1,\n",
       " 'audience': 1,\n",
       " 'designed': 1,\n",
       " 'clubhouses': 1,\n",
       " 'golf': 1,\n",
       " 'courses.': 1,\n",
       " 'beautiful': 1,\n",
       " 'facility.': 1,\n",
       " 'immediately': 1,\n",
       " 'use.': 1,\n",
       " \"wouldn't\": 1,\n",
       " 'man': 4,\n",
       " 'needed': 2,\n",
       " 'paid,': 1,\n",
       " 'charging': 1,\n",
       " 'do...': 1,\n",
       " 'to...': 1,\n",
       " 'Do': 1,\n",
       " 'thousands': 1,\n",
       " 'course': 1,\n",
       " 'apology': 1,\n",
       " 'someone': 2,\n",
       " 'labor,': 1,\n",
       " 'goods': 1,\n",
       " 'produced,': 1,\n",
       " 'them?': 1,\n",
       " 'certainly': 2,\n",
       " 'relieved': 1,\n",
       " 'late': 1,\n",
       " 'provided': 1,\n",
       " 'expected': 1,\n",
       " 'bargain': 1,\n",
       " 'sides.': 1,\n",
       " 'bankruptcy': 2,\n",
       " 'six': 1,\n",
       " 'times.': 1,\n",
       " 'great': 2,\n",
       " 'businesspeople': 1,\n",
       " 'once.': 1,\n",
       " 'yourself': 1,\n",
       " 'King': 1,\n",
       " 'Debt.': 1,\n",
       " 'leverage.': 1,\n",
       " 'suggested': 1,\n",
       " 'try': 4,\n",
       " 'negotiate': 1,\n",
       " 'States.': 1,\n",
       " 'sometimes': 4,\n",
       " 'direct': 2,\n",
       " 'transfer': 1,\n",
       " 'skills': 1,\n",
       " 'government,': 1,\n",
       " 'happened': 1,\n",
       " 'bad': 1,\n",
       " 'government.': 1,\n",
       " 'right.': 1,\n",
       " 'Race': 1,\n",
       " 'remains': 1,\n",
       " 'significant': 1,\n",
       " 'Unfortunately,': 1,\n",
       " 'race': 1,\n",
       " 'still': 3,\n",
       " 'determines': 4,\n",
       " 'too': 9,\n",
       " 'much,': 1,\n",
       " 'often': 1,\n",
       " 'live,': 1,\n",
       " 'education': 1,\n",
       " 'public': 1,\n",
       " 'get,': 1,\n",
       " 'and,': 2,\n",
       " 'yes,': 2,\n",
       " \"they're\": 3,\n",
       " 'treated': 1,\n",
       " 'criminal': 5,\n",
       " 'justice': 5,\n",
       " 'system.': 4,\n",
       " 'two': 5,\n",
       " 'tragic': 1,\n",
       " 'examples': 1,\n",
       " 'Tulsa': 1,\n",
       " 'Charlotte.': 1,\n",
       " 'several': 1,\n",
       " 'time.': 2,\n",
       " 'restore': 2,\n",
       " 'trust': 1,\n",
       " 'between': 1,\n",
       " 'communities': 6,\n",
       " 'police.': 3,\n",
       " 'police': 8,\n",
       " 'training,': 2,\n",
       " 'techniques,': 1,\n",
       " 'well': 3,\n",
       " 'prepared': 3,\n",
       " 'use': 4,\n",
       " 'force': 1,\n",
       " 'necessary.': 1,\n",
       " 'Everyone': 1,\n",
       " 'respected': 1,\n",
       " 'law,': 1,\n",
       " 'respect': 3,\n",
       " 'law.': 1,\n",
       " 'Right': 2,\n",
       " 'now,': 2,\n",
       " 'case': 1,\n",
       " 'neighborhoods.': 2,\n",
       " 'day': 1,\n",
       " 'campaign,': 1,\n",
       " 'reform.': 2,\n",
       " 'platform': 1,\n",
       " 'begin': 2,\n",
       " 'remedy': 1,\n",
       " 'problems': 5,\n",
       " 'recognize,': 1,\n",
       " 'addition': 1,\n",
       " 'challenges': 2,\n",
       " 'policing,': 2,\n",
       " 'good,': 1,\n",
       " 'brave': 1,\n",
       " 'officers': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-level code that calls the above functions for each of the files\n",
    "# 'debate-clinton.txt' and 'debate-trump.txt'.\n",
    "# You probably also want to print out a blank line separator dividing the files and saying which you are printing.\n",
    "\n",
    "clinton_words = word_counter('debate-clinton.txt')\n",
    "\n",
    "#print_word_count(trump_words)\n",
    "\n",
    "clinton_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb2750",
   "metadata": {},
   "source": [
    "Let's now try to make that program a bit better! You can just edit it above and leave the final program.\n",
    "\n",
    "1. Although it was useful to learn about `if` control structures – and we will use them a lot – you don't actually need to use one here. Do you instead remember about the `get(<key>, <default>)` method on a dict that we saw earlier? Try using it. *(Warning: this can be challenging so it is fine to skip it at first and come back later)*.\n",
    "\n",
    "2. The above code is hardcoded to print words that occur 2 or more times. This makes the list shorter by leaving out words that occur only once (the \"hapax legomena\" of the list — there are always a lot of these, often about 40% of the word types). But it's still a long list. We might want to only print words that occur 3 or more times, say. Make the minimum number of times for a word to occur to print it another parameter of the second function, and have the top-level code call it with the value 3.\n",
    "\n",
    "3. At the other extreme, it might not be very interesting knowing how often the candidates say \"the\" or \"to\". Such function words often don't seem to carry much content. (Though, of course, be aware of the work of people such as [James Pennebaker](http://www.secretlifeofpronouns.com/), who emphasizes how much social meaning can be conveyed by function words. Lists of common function words that you are not going to count are conventionally called **stop words** in computational work. Modify the first program to also accept a list of stop words which you don't put in the hash. Modify the top-level code so that it doesn't count `['the', 'a', 'an', 'that', 'and', 'to', 'of']`\n",
    "\n",
    "4. We're starting to suffer badly from simply tokenizing by dividing on whitespace. We could do a little better by simply \"whiting out\" the commonest punctuation marks that glom on to words. Before splitting on white space, we could change the string to delete letters like: `'.', ',', '\"'`. Remember the `replace()` method on `str` that we saw last time. Look at your output, you may well want to delete a few more. Doing this will do a little textual damage; e.g., `30,000` will become `30000`, but it won't be too bad. You may want to not delete `'`, though, so that you don't damage words like `isn't`.\n",
    "\n",
    "5. It might also be useful to lowercase all tokens, so that words don't become different just because they are at the start of a sentence. Of course, you'll then just have to be smart enough to recognize that `irs` means the `IRS`.\n",
    "\n",
    "6. It would be good to also add up how many non-stop words were spoken by each candidate. Who spoke the most?\n",
    "\n",
    "7. To normalize for frequency, it would be useful to also work out the percent of times the word each candidate says is a certain word. So, in the second function, also print the percent as well as the raw count.\n",
    "\n",
    "8. Find at least one interesting difference in word use between the two candidates, and put it in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bef4b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jeg er en string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jeg', 'er', 'en', 'string']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"Jeg eR en strIng\"\n",
    "test_string_split = test_string.split()\n",
    "\n",
    "test_string_l = test_string.lower()\n",
    "print(test_string_l)\n",
    "\n",
    "test_string_l2 = []\n",
    "for word in test_string_split:\n",
    "    test_string_l2.append(word.lower())\n",
    "    \n",
    "test_string_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb8bfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def good_word_counter(file_name, list_stopwords):\n",
    "    \n",
    "    text_file = open(file_name)\n",
    "    word_count_dict = {}\n",
    "    \n",
    "    \n",
    "    for line in text_file:\n",
    "        # get rid of the line break at the end\n",
    "        line = line.strip()\n",
    "        line = line.lower()\n",
    "        \n",
    "        punc = [\".\", \",\", \"?\", \"-\"]\n",
    "        \n",
    "        for punctuation in punc:\n",
    "            line = line.replace(punctuation, \"\")\n",
    "            \n",
    "        # split sentence along spaces\n",
    "        sentence = line.split()\n",
    "        \n",
    "        # go through words\n",
    "        for word in sentence:\n",
    "            if word not in list_stopwords:\n",
    "            # check whether word is already in dictionary\n",
    "                word_count_dict[word] = word_count_dict.get(word, 0) + 1\n",
    "                \n",
    "    text_file.close()\n",
    "    \n",
    "    return word_count_dict\n",
    "\n",
    "def good_print_word_count(word_count_dict, freq):\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    for (word, frequency) in word_count_dict.items():\n",
    "        total += frequency\n",
    "\n",
    "    for (word, frequency) in word_count_dict.items():\n",
    "        if frequency >= freq:\n",
    "            print(word, frequency, frequency * 100 / total)\n",
    "            \n",
    "    return total\n",
    "            \n",
    "            \n",
    "stop_words = ['the', 'a', 'an', 'that', 'and', 'to', 'of']\n",
    "\n",
    "word_count = good_word_counter('debate-clinton.txt', stop_words)\n",
    "\n",
    "#good_print_word_count(word_count, 10)\n",
    "\n",
    "word_count['great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258e5795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "currently printing the word count for file: debate-trump.txt\n",
      "you 200 2.8776978417266186\n",
      "lester 11 0.15827338129496402\n",
      "our 60 0.8633093525179856\n",
      "jobs 18 0.2589928057553957\n",
      "are 55 0.7913669064748201\n",
      "country 49 0.7050359712230215\n",
      "they're 40 0.5755395683453237\n",
      "going 46 0.6618705035971223\n",
      "many 28 0.4028776978417266\n",
      "other 19 0.2733812949640288\n",
      "countries 12 0.17266187050359713\n",
      "look 44 0.6330935251798561\n",
      "at 45 0.6474820143884892\n",
      "what 42 0.60431654676259\n",
      "is 79 1.1366906474820144\n",
      "doing 29 0.4172661870503597\n",
      "in 108 1.5539568345323742\n",
      "their 19 0.2733812949640288\n",
      "them 37 0.5323741007194245\n",
      "we 122 1.7553956834532374\n",
      "have 143 2.0575539568345325\n",
      "very 71 1.0215827338129497\n",
      "good 18 0.2589928057553957\n",
      "because 58 0.8345323741007195\n",
      "as 29 0.4172661870503597\n",
      "thing 21 0.302158273381295\n",
      "so 46 0.6618705035971223\n",
      "we're 25 0.3597122302158273\n",
      "when 42 0.60431654676259\n",
      "said 37 0.5323741007194245\n",
      "it's 72 1.0359712230215827\n",
      "world 14 0.2014388489208633\n",
      "some 19 0.2733812949640288\n",
      "with 52 0.7482014388489209\n",
      "he 14 0.2014388489208633\n",
      "not 52 0.7482014388489209\n",
      "much 19 0.2733812949640288\n",
      "leaving 15 0.2158273381294964\n",
      "see 11 0.15827338129496402\n",
      "all 43 0.6187050359712231\n",
      "can't 18 0.2589928057553957\n",
      "it 121 1.7410071942446044\n",
      "things 21 0.302158273381295\n",
      "i 230 3.3093525179856114\n",
      "think 37 0.5323741007194245\n",
      "agree 13 0.18705035971223022\n",
      "on 45 0.6474820143884892\n",
      "do 53 0.762589928057554\n",
      "but 79 1.1366906474820144\n",
      "be 52 0.7482014388489209\n",
      "about 34 0.4892086330935252\n",
      "from 23 0.33093525179856115\n",
      "us 15 0.2158273381294964\n",
      "companies 20 0.28776978417266186\n",
      "people 33 0.4748201438848921\n",
      "take 13 0.18705035971223022\n",
      "they 69 0.9928057553956835\n",
      "this 46 0.6618705035971223\n",
      "my 15 0.2158273381294964\n",
      "i'll 11 0.15827338129496402\n",
      "for 41 0.5899280575539568\n",
      "that's 29 0.4172661870503597\n",
      "like 22 0.31654676258992803\n",
      "will 30 0.4316546762589928\n",
      "new 18 0.2589928057553957\n",
      "these 20 0.28776978417266186\n",
      "well 22 0.31654676258992803\n",
      "one 25 0.3597122302158273\n",
      "me 36 0.5179856115107914\n",
      "into 13 0.18705035971223022\n",
      "say 31 0.4460431654676259\n",
      "don't 31 0.4460431654676259\n",
      "know 27 0.38848920863309355\n",
      "over 18 0.2589928057553957\n",
      "ever 14 0.2014388489208633\n",
      "tax 14 0.2014388489208633\n",
      "no 27 0.38848920863309355\n",
      "been 38 0.5467625899280576\n",
      "time 14 0.2014388489208633\n",
      "years 22 0.31654676258992803\n",
      "politicians 10 0.14388489208633093\n",
      "done 11 0.15827338129496402\n",
      "now 22 0.31654676258992803\n",
      "secretary 27 0.38848920863309355\n",
      "clinton 22 0.31654676258992803\n",
      "want 23 0.33093525179856115\n",
      "she 29 0.4172661870503597\n",
      "was 67 0.9640287769784173\n",
      "really 19 0.2733812949640288\n",
      "she's 11 0.15827338129496402\n",
      "why 10 0.14388489208633093\n",
      "better 11 0.15827338129496402\n",
      "just 39 0.5611510791366906\n",
      "should 25 0.3597122302158273\n",
      "right 13 0.18705035971223022\n",
      "trillion 12 0.17266187050359713\n",
      "first 10 0.14388489208633093\n",
      "could 15 0.2158273381294964\n",
      "there 12 0.17266187050359713\n",
      "than 11 0.15827338129496402\n",
      "go 19 0.2733812949640288\n",
      "or 18 0.2589928057553957\n",
      "lot 15 0.2158273381294964\n",
      "if 21 0.302158273381295\n",
      "you're 16 0.2302158273381295\n",
      "your 19 0.2733812949640288\n",
      "bring 15 0.2158273381294964\n",
      "wrong 11 0.15827338129496402\n",
      "i'm 30 0.4316546762589928\n",
      "by 25 0.3597122302158273\n",
      "way 20 0.28776978417266186\n",
      "did 21 0.302158273381295\n",
      "money 17 0.2446043165467626\n",
      "great 15 0.2158273381294964\n",
      "out 26 0.37410071942446044\n",
      "tell 15 0.2158273381294964\n",
      "where 16 0.2302158273381295\n",
      "back 14 0.2014388489208633\n",
      "which 14 0.2014388489208633\n",
      "deal 11 0.15827338129496402\n",
      "were 21 0.302158273381295\n",
      "how 10 0.14388489208633093\n",
      "bad 13 0.18705035971223022\n",
      "would 20 0.28776978417266186\n",
      "against 12 0.17266187050359713\n",
      "president 11 0.15827338129496402\n",
      "tremendous 11 0.15827338129496402\n",
      "i've 10 0.14388489208633093\n",
      "even 11 0.15827338129496402\n",
      "also 10 0.14388489208633093\n",
      "her 20 0.28776978417266186\n",
      "isis 13 0.18705035971223022\n",
      "believe 15 0.2158273381294964\n",
      "get 26 0.37410071942446044\n",
      "doesn't 11 0.15827338129496402\n",
      "more 14 0.2014388489208633\n",
      "has 15 0.2158273381294964\n",
      "taken 10 0.14388489208633093\n",
      "up 13 0.18705035971223022\n",
      "had 12 0.17266187050359713\n",
      "need 13 0.18705035971223022\n",
      "got 13 0.18705035971223022\n",
      "community 10 0.14388489208633093\n",
      "nato 10 0.14388489208633093\n",
      "war 12 0.17266187050359713\n",
      "in this file, the total number of words spoken were 6950\n",
      "===========================\n",
      "currently printing the word count for file: debate-clinton.txt\n",
      "how 13 0.2748414376321353\n",
      "are 38 0.8033826638477801\n",
      "you 71 1.5010570824524312\n",
      "donald 21 0.4439746300211416\n",
      "well 35 0.7399577167019028\n",
      "for 42 0.8879492600422833\n",
      "us 21 0.4439746300211416\n",
      "in 96 2.029598308668076\n",
      "this 32 0.6765327695560254\n",
      "is 56 1.1839323467230445\n",
      "really 19 0.40169133192389006\n",
      "what 39 0.8245243128964059\n",
      "kind 10 0.21141649048625794\n",
      "country 16 0.3382663847780127\n",
      "we 128 2.7061310782241015\n",
      "want 20 0.42283298097251587\n",
      "be 57 1.2050739957716703\n",
      "my 10 0.21141649048625794\n",
      "so 40 0.8456659619450317\n",
      "i 134 2.8329809725158563\n",
      "think 39 0.8245243128964059\n",
      "about 34 0.718816067653277\n",
      "lot 18 0.38054968287526425\n",
      "have 84 1.7758985200845665\n",
      "economy 13 0.2748414376321353\n",
      "not 39 0.8245243128964059\n",
      "just 14 0.2959830866807611\n",
      "at 33 0.6976744186046512\n",
      "need 23 0.48625792811839325\n",
      "new 13 0.2748414376321353\n",
      "jobs 16 0.3382663847780127\n",
      "good 16 0.3382663847780127\n",
      "with 35 0.7399577167019028\n",
      "your 23 0.48625792811839325\n",
      "business 15 0.3171247357293869\n",
      "because 22 0.46511627906976744\n",
      "will 21 0.4439746300211416\n",
      "from 17 0.3594080338266385\n",
      "also 13 0.2748414376321353\n",
      "make 16 0.3382663847780127\n",
      "work 15 0.3171247357293869\n",
      "see 10 0.21141649048625794\n",
      "more 21 0.4439746300211416\n",
      "do 47 0.9936575052854123\n",
      "if 16 0.3382663847780127\n",
      "should 15 0.3171247357293869\n",
      "them 19 0.40169133192389006\n",
      "people 31 0.6553911205073996\n",
      "who 21 0.4439746300211416\n",
      "i've 11 0.23255813953488372\n",
      "many 11 0.23255813953488372\n",
      "going 25 0.5285412262156448\n",
      "it 59 1.2473572938689217\n",
      "we're 18 0.38054968287526425\n",
      "by 12 0.2536997885835095\n",
      "their 19 0.40169133192389006\n",
      "on 26 0.5496828752642706\n",
      "it's 20 0.42283298097251587\n",
      "our 39 0.8245243128964059\n",
      "can 29 0.6131078224101479\n",
      "tax 16 0.3382663847780127\n",
      "has 29 0.6131078224101479\n",
      "would 39 0.8245243128964059\n",
      "all 12 0.2536997885835095\n",
      "we've 17 0.3594080338266385\n",
      "that's 18 0.38054968287526425\n",
      "know 23 0.48625792811839325\n",
      "was 26 0.5496828752642706\n",
      "very 12 0.2536997885835095\n",
      "his 13 0.2748414376321353\n",
      "he 42 0.8879492600422833\n",
      "million 10 0.21141649048625794\n",
      "out 16 0.3382663847780127\n",
      "there 19 0.40169133192389006\n",
      "don't 10 0.21141649048625794\n",
      "one 19 0.40169133192389006\n",
      "said 15 0.3171247357293869\n",
      "go 10 0.21141649048625794\n",
      "some 13 0.2748414376321353\n",
      "been 11 0.23255813953488372\n",
      "but 36 0.7610993657505285\n",
      "up 11 0.23255813953488372\n",
      "get 16 0.3382663847780127\n",
      "got 14 0.2959830866807611\n",
      "look 10 0.21141649048625794\n",
      "when 18 0.38054968287526425\n",
      "they 24 0.507399577167019\n",
      "as 23 0.48625792811839325\n",
      "no 10 0.21141649048625794\n",
      "he's 11 0.23255813953488372\n",
      "too 10 0.21141649048625794\n",
      "communities 10 0.21141649048625794\n",
      "police 11 0.23255813953488372\n",
      "in this file, the total number of words spoken were 4730\n"
     ]
    }
   ],
   "source": [
    "list_file_names = ['debate-trump.txt', 'debate-clinton.txt']\n",
    "\n",
    "for i in list_file_names:\n",
    "    print(\"===========================\")\n",
    "    print(f\"currently printing the word count for file: {i}\")\n",
    "    word_count = good_word_counter(i, stop_words)\n",
    "    total_count = good_print_word_count(word_count, 10)\n",
    "    print(f\"in this file, the total number of words spoken were {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3306f34",
   "metadata": {},
   "source": [
    "### Bonus: Getting word counts from the Google Books data\n",
    "\n",
    "The raw data files for the Google Books collection are available for \n",
    "download. The files are huge, so I created a tiny sample in the file `googlebooks-eng-all-1gram-20120701-a-sample`.\n",
    "\n",
    "The format of this file is as follows (whitespace inserted for \n",
    "readability):\n",
    "\n",
    "```\n",
    "word TAB year TAB match_count TAB volume_count NEWLINE\n",
    "```\n",
    "\n",
    "The TAB character is \"\\t\", which you can treat like any other (for\n",
    "example, you can split a string on \"\\t\"). The `match_count` is how many times the word occurred and the `volume_count` is a smaller number for how many _different_ books it occurred in. We will use the `match_count`. Note that the words have also been disambiguated by part of speech where ambiguous. We'll get to that later.\n",
    "\n",
    "Your first task: complete googlebooks_counts_by_year so that it processes\n",
    "my sample file and returns a 2d dictionary (a top-level dictionary whose values are each a dictionary!) with this structure:\n",
    "\n",
    "{\n",
    "  word1: {year1: count, year2: count ...},\n",
    "  word2: {year1: count, year2: count ...},\n",
    "  ...\n",
    "}\n",
    "\n",
    "where the contents of the year dicts is determined by the file.\n",
    "(That is, different words will have different years and counts\n",
    "associated with them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da993a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlebooks_counts_by_year(filename):\n",
    "    \"\"\"Maps a Google books 1-grams file to a 2d dictionary\n",
    "    giving each word's counts by year.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85223e2f",
   "metadata": {},
   "source": [
    "Second task: Complete the function googlebooks_year_collapse so that it takes as input the output of googlebooks_counts_by_year and collapses\n",
    "it down so that each word is associated with its single tokencount\n",
    "for the full, obtained by summing up all of the counts for the\n",
    "years associated with that word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ada65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlebooks_year_collapse(d):\n",
    "    \"\"\"Convert the output of googlebooks_counts_by_year to \n",
    "    a simpler dict mapping words to counts.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46e98e",
   "metadata": {},
   "source": [
    "Write something at the top-level to call this code on the file `googlebooks-eng-all-1gram-20120701-a-sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbd799be",
   "metadata": {},
   "source": [
    "## Part 2: Regular Expressions in Python\n",
    "\n",
    "Regular expressions – regex – are super useful when processing text in Python! However, there are so many different patterns and ways to use the re module that it is impossible to learn by heart. So instead, this part of the HW is for you to play around and get comfortable with using regex. Also, head to [regex101.com](http://www.regex101.com/) for a nice place to test out your regex patterns before running them here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "657b91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[a-z]+', re.UNICODE)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('[a-z]+')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2718541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='temp'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a few different things instead of 'tempo' - can you find the things that don't match?\n",
    "m = p.match('temp0')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abfd5481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0be1c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.start(), m.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa1b7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(p.match('::: message'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42413e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 11), match='message'>\n"
     ]
    }
   ],
   "source": [
    "m = p.search('::: message'); print(m)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f408dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found:  a\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('[a-z]+')\n",
    "m = p.search( '2942a9vv4dxaq42' )\n",
    "if m:\n",
    "    print('Match found: ', m.group())\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbe6c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'vv', 'dxaq']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.findall('2942a9vv4dxaq42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "194b1987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='From '>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shortcut pattern and matcher in one!\n",
    "re.match(r'From\\s+', 'From amk Thu May 14 19:12:10 1998')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cde418",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a682003",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('(a(b)c)d')\n",
    "m = p.match('abcd')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75425f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e183a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1345 Cowper St'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'(\\d+)\\s+(\\w+)\\s+St')\n",
    "m = p.search('I live at 1345 Cowper St')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51b66854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1345'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "607c0624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cowper'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66e8b80",
   "metadata": {},
   "source": [
    "### Substitutions in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da645fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('(blue|white|red)')\n",
    "p.sub('colour', 'blue socks and red shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f10b58",
   "metadata": {},
   "source": [
    "### Splitting on a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0139153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'As',\n",
       " 'wet',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'said',\n",
       " 'Alice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'melancholy',\n",
       " 'tone',\n",
       " 'it',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'dry',\n",
       " 'me',\n",
       " 'at',\n",
       " 'all',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A slightly better word tokenizer\n",
    "# The re split method returns you things that MATCH\n",
    "# the regular expression and skips stuff in between\n",
    "s = '''\\'As wet as ever,\\' said Alice\n",
    "    in a melancholy tone: \\'it doesn\\'t seem to\n",
    "    dry me at all.\\''''\n",
    "p = re.compile('\\W+')\n",
    "p.split(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95461c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'As',\n",
       " 'wet',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'said',\n",
       " 'Alice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'melancholy',\n",
       " 'tone',\n",
       " 'it',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'dry',\n",
       " 'me',\n",
       " 'at',\n",
       " 'all',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again you can shortcut this.\n",
    "re.split('\\W+', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963176a2",
   "metadata": {},
   "source": [
    "Finally, I might note that there's even more complex and sometimes useful stuff you can do with regex that hasn't yet been covered. You can find all the glorious and messy details in the Python 3 library documentation: Case insensitivity, non-capturing groups, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d30d55",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709ea922",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = (\n",
    "    \"\"\"@Becky17 - i'm having a little trouble \"getting\"<br /> the whole twibes thing (but sometimes u gotta just get in there and try it).  :-)\"\"\",\n",
    "    \"\"\"Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\"\"\",\n",
    "    \"\"\"blade--trinity;;; sweeeeeeet. :)\"\"\",\n",
    "    \"\"\"@renay Thanks Renay! $9,000 yay =)\"\"\",\n",
    "    \"\"\"@denvy can try :) drop a tweet with \"##awaresg_tshirts\" so i can <strong>track</strong> orders #awaresg\"\"\",\n",
    "    \"\"\"U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\"\"\",\n",
    "    \"\"\"@LadyB84 Manchester United??? Really??? Breaks my heart :-(http://www.twitpic.com/4x1fn\"\"\",\n",
    "    \"\"\"Can't wait till tomorrow =D\"\"\",\n",
    "    \"\"\"Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\"\"\",\n",
    "    \"\"\"Contact email@address.org today\"\"\",\n",
    "    \"\"\"@linguist278: Variations on phone numbers: +1 (800) 123-4567, (800) 123-4567. Not a real tweet!\"\"\",\n",
    "    \"\"\"RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccbec4",
   "metadata": {},
   "source": [
    "Write a function that takes a list of strings, texts, and a regular expression, regex, as input and prints to standard output the subset that match regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f267d273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\n",
      "U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\n",
      "Can't wait till tomorrow =D\n",
      "Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\n",
      "Contact email@address.org today\n",
      "RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\n"
     ]
    }
   ],
   "source": [
    "def matcher(texts, regex):\n",
    "    \"\"\"Takes a list of strings texts as input and prints to standard output the subset that match regex.\"\"\"\n",
    "    p = re.compile(regex)\n",
    "    \n",
    "    for i in texts:\n",
    "        if p.findall(i):\n",
    "            print(i)\n",
    "\n",
    "matcher(tweets, '^[A-Z]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d319e41",
   "metadata": {},
   "source": [
    "Use this function to test out writing a few regular expressions, testing on the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bef8aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\n",
      "@denvy can try :) drop a tweet with \"##awaresg_tshirts\" so i can <strong>track</strong> orders #awaresg\n",
      "U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\n",
      "Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\n",
      "RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\n"
     ]
    }
   ],
   "source": [
    "def contains_hashtag(texts):\n",
    "    \"\"\"Uses matcher to find tweets that contain a hashtag. Assume a hashtag begins with # and has a non-null sequence of non-space characters after it.\"\"\"\n",
    "    matcher(texts, '(|.*W)#\\S+.*')\n",
    "\n",
    "contains_hashtag(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "360a9561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@renay Thanks Renay! $9,000 yay =)\n"
     ]
    }
   ],
   "source": [
    "def contains_money(texts):\n",
    "    \"\"\"Uses matcher to find tweets that contain a money amount. Assume a money amount begins with $ and has a non-null sequence of digits and periods after it.\"\"\"\n",
    "    matcher(texts, '.*\\$(\\d|\\.)+.*')\n",
    "    \n",
    "contains_money(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bba03b",
   "metadata": {},
   "source": [
    "Write a function that takes a list of strings, texts, and a regular expression, regex, as input and prints to standard output the substrings of each string that match regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0cf3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searcher(texts, regex):\n",
    "    \"\"\"Takes a list of strings texts as input and prints to standard output the substrings of each that match regex.\"\"\"\n",
    "    p = re.compile(regex)\n",
    "    \n",
    "    for i in texts:\n",
    "        m = p.findall(i)\n",
    "        if m:\n",
    "            # printing all the matches as a list\n",
    "            print(m)\n",
    "            \n",
    "            # printing each match by itself:\n",
    "            #for j in m:\n",
    "               # print(j)\n",
    "                \n",
    "#searcher(tweets, '^[A-Z]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf6ae5",
   "metadata": {},
   "source": [
    "Use this function to test out writing a few regular expressions, testing on the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcc8fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smileys(texts):\n",
    "    \"\"\"Uses searcher to find smiley faces, such as :) that appear in the list of strings, texts.\"\"\"\n",
    "    searcher(texts, '[:;=]-?[)(pPD3]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8e5901a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':-)']\n",
      "[':D']\n",
      "[':)']\n",
      "['=)']\n",
      "[':)']\n",
      "[':)']\n",
      "[':-(']\n",
      "['=D']\n",
      "[':-)']\n"
     ]
    }
   ],
   "source": [
    "smileys(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e296fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':)', ':D', ':-(']\n"
     ]
    }
   ],
   "source": [
    "example_text = [\"Yes. :) I'm really happy. :D Except when I'm sad. :-(\"]\n",
    "smileys(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813be0c0",
   "metadata": {},
   "source": [
    "Use the included file words-english.txt and search it \n",
    "for words that have a consonant cluster of 4 or more consonants at the end. We're just using a count of four orthographic consonants, not sounds (phonemes). We won't count y since it is usally a vowel at the end of words.\n",
    "\n",
    "Complete the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb091646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_consonant_clusters(filename):\n",
    "    consonants = \"bcdfghjklmnpqrstvwxz\" # 'y' left out for added interest\n",
    "    \n",
    "    pattern = '[' + consonants + ']{4}$'  # {4,} will take from four and up, {4} means exactly four consonants\n",
    "    p = re.compile(pattern)\n",
    "    \n",
    "    answer  = []\n",
    "    \n",
    "    file = open(filename)\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        m = p.search(line)\n",
    "        \n",
    "        if m: \n",
    "            answer.append(line)\n",
    "            \n",
    "    file.close()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07796d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amongst',\n",
       " 'angst',\n",
       " 'arclength',\n",
       " 'eighth',\n",
       " 'Ernst',\n",
       " 'Hirsch',\n",
       " 'length',\n",
       " 'Messrs',\n",
       " 'strength',\n",
       " 'thousandth',\n",
       " 'twelfth',\n",
       " 'unbeknownst',\n",
       " 'warmth',\n",
       " 'wavelength']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_consonant_clusters('words-english.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ef0ef",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use the included file gaddafi.txt and write a regular expression to match instances of his surname. You should match the first 112 but not the last 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b888712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qaddafi, Muammar\n",
      "\n",
      "Al-Gathafi, Muammar\n",
      "\n",
      "al-Qadhafi, Muammar\n",
      "\n",
      "Al Qathafi, Mu'ammar\n",
      "\n",
      "Al Qathafi, Muammar\n",
      "\n",
      "El Gaddafi, Moamar\n",
      "\n",
      "El Kadhafi, Moammar\n",
      "\n",
      "El Kazzafi, Moamer\n",
      "\n",
      "El Qathafi, Mu'Ammar\n",
      "\n",
      "Gadafi, Muammar\n",
      "\n",
      "Gaddafi, Moamar\n",
      "\n",
      "Gadhafi, Mo'ammar\n",
      "\n",
      "Gathafi, Muammar\n",
      "\n",
      "Ghadafi, Muammar\n",
      "\n",
      "Ghaddafi, Muammar\n",
      "\n",
      "Ghaddafy, Muammar\n",
      "\n",
      "Gheddafi, Muammar\n",
      "\n",
      "Gheddafi, Muhammar\n",
      "\n",
      "Kadaffi, Momar\n",
      "\n",
      "Kad'afi, Mu`amar al- 20\n",
      "\n",
      "Kaddafi, Muamar\n",
      "\n",
      "Kaddafi, Muammar\n",
      "\n",
      "Kadhafi, Moammar\n",
      "\n",
      "Kadhafi, Mouammar\n",
      "\n",
      "Kazzafi, Moammar\n",
      "\n",
      "Khadafy, Moammar\n",
      "\n",
      "Khaddafi, Muammar\n",
      "\n",
      "Moamar al-Gaddafi\n",
      "\n",
      "Moamar el Gaddafi\n",
      "\n",
      "Moamar El Kadhafi\n",
      "\n",
      "Moamar Gaddafi\n",
      "\n",
      "Moamer El Kazzafi\n",
      "\n",
      "Mo'ammar el-Gadhafi\n",
      "\n",
      "Moammar El Kadhafi\n",
      "\n",
      "Mo'ammar Gadhafi\n",
      "\n",
      "Moammar Kadhafi\n",
      "\n",
      "Moammar Khadafy\n",
      "\n",
      "Moammar Qudhafi\n",
      "\n",
      "Mu`amar al-Kad'afi\n",
      "\n",
      "Mu'amar al-Kadafi\n",
      "\n",
      "Muamar Al-Kaddafi\n",
      "\n",
      "Muamar Kaddafi\n",
      "\n",
      "Muamer Gadafi\n",
      "\n",
      "Muammar Al-Gathafi\n",
      "\n",
      "Muammar al-Khaddafi\n",
      "\n",
      "Mu'ammar al-Qadafi\n",
      "\n",
      "Mu'ammar al-Qaddafi\n",
      "\n",
      "Muammar al-Qadhafi\n",
      "\n",
      "Mu'ammar al-Qadhdhafi\n",
      "\n",
      "Mu`ammar al-Qadhdhafi 50\n",
      "\n",
      "Mu'ammar Al Qathafi\n",
      "\n",
      "Muammar Al Qathafi\n",
      "\n",
      "Muammar Gadafi\n",
      "\n",
      "Muammar Gaddafi\n",
      "\n",
      "Muammar Ghadafi\n",
      "\n",
      "Muammar Ghaddafi\n",
      "\n",
      "Muammar Ghaddafy\n",
      "\n",
      "Muammar Gheddafi\n",
      "\n",
      "Muammar Kaddafi\n",
      "\n",
      "Muammar Khaddafi\n",
      "\n",
      "Mu'ammar Qadafi\n",
      "\n",
      "Muammar Qaddafi\n",
      "\n",
      "Muammar Qadhafi\n",
      "\n",
      "Mu'ammar Qadhdhafi\n",
      "\n",
      "Muammar Quathafi\n",
      "\n",
      "Mulazim Awwal Mu'ammar Muhammad Abu Minyar al-Qadhafi\n",
      "\n",
      "Qadafi, Mu'ammar\n",
      "\n",
      "Qadhafi, Muammar\n",
      "\n",
      "Qadhdhafi, Mu`ammar\n",
      "\n",
      "Qathafi, Mu'Ammar el 70\n",
      "\n",
      "Quathafi, Muammar\n",
      "\n",
      "Qudhafi, Moammar\n",
      "\n",
      "Moamar AI Kadafi\n",
      "\n",
      "Maummar Gaddafi\n",
      "\n",
      "Moamar Gadhafi\n",
      "\n",
      "Moamer Gaddafi\n",
      "\n",
      "Moamer Kadhafi\n",
      "\n",
      "Moamma Gaddafi\n",
      "\n",
      "Moammar Gaddafi\n",
      "\n",
      "Moammar Gadhafi\n",
      "\n",
      "Moammar Ghadafi\n",
      "\n",
      "Moammar Khadaffy\n",
      "\n",
      "Moammar Khaddafi\n",
      "\n",
      "Moammar el Gadhafi\n",
      "\n",
      "Moammer Gaddafi\n",
      "\n",
      "Mouammer al Gaddafi\n",
      "\n",
      "Muamar Gaddafi\n",
      "\n",
      "Muammar Al Ghaddafi\n",
      "\n",
      "Muammar Al Qaddafi\n",
      "\n",
      "Muammar Al Qaddafi\n",
      "\n",
      "Muammar El Qaddafi\n",
      "\n",
      "Muammar Gadaffi\n",
      "\n",
      "Muammar Gadafy\n",
      "\n",
      "Muammar Gaddhafi\n",
      "\n",
      "Muammar Gadhafi\n",
      "\n",
      "Muammar Ghadaffi\n",
      "\n",
      "Muammar Qadthafi\n",
      "\n",
      "Muammar al Gaddafi\n",
      "\n",
      "Muammar el Gaddafy\n",
      "\n",
      "Muammar el Gaddafi\n",
      "\n",
      "Muammar el Qaddafi\n",
      "\n",
      "Muammer Gadaffi\n",
      "\n",
      "Muammer Gaddafi\n",
      "\n",
      "Mummar Gaddafi\n",
      "\n",
      "Omar Al Qathafi\n",
      "\n",
      "Omar Mouammer Al Gaddafi\n",
      "\n",
      "Omar Muammar Al Ghaddafi\n",
      "\n",
      "Omar Muammar Al Qaddafi\n",
      "\n",
      "Omar Muammar Al Qathafi\n",
      "\n",
      "Omar Muammar Gaddafi\n",
      "\n",
      "Omar Muammar Ghaddafi\n",
      "\n",
      "Omar al Ghaddafi\n",
      "\n",
      "# I think you shouldn't find these ones\n",
      "\n",
      "Gagafy\n",
      "\n",
      "Mummar Gadddafi\n",
      "\n",
      "Quudafi, Muammar\n",
      "\n",
      "Qudai, Muammar\n",
      "\n",
      "Quhafi, Muammar\n",
      "\n",
      "Mummar Gaddafiy\n",
      "\n",
      "Mummar Gadaf\n",
      "\n",
      "Omar Qaafi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gad = open('gaddafi.txt')\n",
    "\n",
    "for i in gad:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "883042fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaddafi_matches(filename):\n",
    "    \n",
    "    first = \"(M(o|u|ou)(['`h]?[aA])?|O|Mau)mm?[ea]r?\"\n",
    "    pre_last = \"([AEae][lI][- ])?\"\n",
    "    main_last = \"[KQG]h?(a|ua|e|u)([dt]h?(d|h|'|[td]h)?|zz)aff?[iy]\"\n",
    "    \n",
    "    last = pre_last + main_last\n",
    "    \n",
    "    forward = first + ' (\\w+ )*' + last + '( |$)'\n",
    "    backward = last + ', ' + first\n",
    "    \n",
    "    pattern = forward + '|' + backward \n",
    "    \n",
    "    p = re.compile(pattern)\n",
    "    \n",
    "    #print(pattern)\n",
    "    matches = 0\n",
    "    \n",
    "    file = open(filename)\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        m = p.search(line)\n",
    "        #print(m)\n",
    "        if m:\n",
    "            #print(line)\n",
    "            matches = matches + 1\n",
    "        else:\n",
    "            print(f\"This did not match: {line}\")\n",
    "    file.close()\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfd1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This did not match: # I think you shouldn't find these ones\n",
      "This did not match: Gagafy\n",
      "This did not match: Mummar Gadddafi\n",
      "This did not match: Quudafi, Muammar\n",
      "This did not match: Qudai, Muammar\n",
      "This did not match: Quhafi, Muammar\n",
      "This did not match: Mummar Gaddafiy\n",
      "This did not match: Mummar Gadaf\n",
      "This did not match: Omar Qaafi\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "total_num_m = gaddafi_matches('gaddafi.txt')\n",
    "\n",
    "print(total_num_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
